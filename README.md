

# Downtime-Dashboard

Project Title: Downtime Analysis Dashboard for renowed Textile Limited

Introduction:

The Downtime Analysis Dashboard for the renowed Textile Limited is a dynamic reporting tool developed using Power BI to provide insightful analyses of downtime occurrences within the company's production operations. As a prominent player in the textile industry, this particular Textile Limited recognizes the criticality of minimizing downtime to ensure operational efficiency and meet customer demands consistently.

Objective:
The primary objective of this project is to offer stakeholders at Hameem Textile Limited a comprehensive view of downtime incidents across various departments, issues, and shifts on a daily basis. By tracking and analyzing downtime data, the dashboard aims to facilitate informed decision-making and strategic planning to enhance production efficiency and optimize resource utilization. Moreover, the dashboard serves as a valuable tool for identifying recurring issues, implementing corrective measures, and driving continuous improvement initiatives to streamline production processes.

Key Features:

*Department-wise breakdown of loss time to identify areas of improvement.
*Issue-wise analysis to pinpoint recurring problems and their impact on production.
*Shift-wise comparison to assess downtime patterns and performance across different shifts.
*Daily reporting functionality to provide real-time insights into downtime trends and fluctuations.
Interactive visualizations and intuitive dashboards for easy interpretation and actionable insights.
*By leveraging the Downtime Analysis Dashboard, Hameem Textile Limited aims to foster a culture of data-driven decision-making, drive operational excellence, and ensure sustained growth and competitiveness in the textile industry.


### Steps followed 

1. Data Loading from Excel:

The option to import data from Excel was selected to begin the process.
The appropriate sheet containing the downtime data was navigated to and selected.
The data was loaded into Power BI by choosing the appropriate option.

2. Application of Changes in Query Editor:

Upon loading the data, Power BI opened the Query Editor window.
Various transformations and cleaning operations were applied to the data to prepare it for analysis.
Tasks such as removing unnecessary columns, renaming columns, changing data types, handling missing values, and merging or appending data from multiple sources were performed.

3. Data Modeling:

Relationships between different tables were established if multiple data tables were present.
Measures and calculated columns were defined as needed to perform calculations and aggregations in the reports.
Hierarchies and formatting options were set up to improve the usability of the data model.

4. Design of Visuals:

Visualizations were created by selecting the appropriate visualizations from the Visualizations pane.
Fields from the data model were dragged and dropped into the appropriate fields in the visualizations to populate them with data.
The appearance of the visualizations was customized by adjusting colors, labels, titles, and other formatting options.
Additional visualizations were added to the report canvas to provide a comprehensive view of the data.

5. Application of Visual Filters and Slicers:

Visual filters and slicers were included to allow users to interactively filter and slice the data based on different criteria such as date, shift, department, etc.
Slicers for date and shift were added to enable users to filter the data based on specific time periods and shifts.

6. Creation of Specific Visualizations:

A bar chart was created to visualize machine-wise loss time, showing the amount of downtime for each machine.
A donut chart was used to display issue-wise loss time, highlighting the distribution of downtime across different issues.
A stacked area chart was utilized to illustrate department-wise loss time over time, showing how downtime varies across different departments.

7. Inclusion of Summary Cards:

Summary cards were included to provide key metrics and totals, such as total hours of downtime, total number of departments affected, total number of issues reported, and total number of machines involved.

8. Formatting and Layout Adjustment:

The formatting and layout of the report were fine-tuned to ensure clarity and consistency.
The size and position of visualizations on the canvas were adjusted to optimize space usage and readability.
Consistent color schemes, fonts, and styling were applied throughout the report to maintain visual coherence.

9. Testing and Validation:

The functionality of the dashboard was tested by interacting with the filters and slicers to ensure that the data responded appropriately.
The accuracy of the visualizations and metrics against the original data source was validated to ensure data integrity.

10. Publishing and Sharing:

Once the dashboard was completed and validated, it was published to the Power BI service to make it accessible to stakeholders.
The dashboard was shared with relevant users or groups within the organization, and appropriate permissions were granted as needed.
Automatic data refreshes were scheduled to keep the dashboard up-to-date with the latest data from the source.


 
 # Report Snapshot (Power BI DESKTOP)

 
![Dashboard_upload](https://github.com/abidurrahman31/Downtime_Report/assets/162081738/da72ab42-af14-4c20-923e-99a02133c074)



https://github.com/user-attachments/assets/3356f9a2-a439-45b8-ab8a-65acf9697427


 



